{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/omidshy/ML/blob/master/src/MB-potential.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FMj6evQUH4rQ"
   },
   "source": [
    "# Modeling the Müller-Brown PES using a Neural Network\n",
    "\n",
    "In this tutorial, we will learn how to use a neural network (NN) model to predict the energy of points on the Müller-Brown potential energy surface.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install plotly\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1y8otrleFRXC"
   },
   "outputs": [],
   "source": [
    "from math import exp, pow, tanh\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G5gEWLszUpQV"
   },
   "source": [
    "## Defining the Müller-Brown Potential\n",
    "\n",
    "Bellow you can see the functional form of the Müller-Brown potential. For more details see [here](https://www.wolframcloud.com/objects/demonstrations/TrajectoriesOnTheMullerBrownPotentialEnergySurface-source.nb).\n",
    "\n",
    "$v(x,y) = \\sum_{k=0}^3 A_k \\mathrm{exp}\\left[ a_k (x - x_k^0)^2 + b_k (x - x_k^0) (y - y_k^0) + c_k (y - y_k^0)^2 \\right] $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define the Müller-Brown potential as a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N0JzzAZ1UZdx"
   },
   "outputs": [],
   "source": [
    "def mueller_brown_potential(x, y):\n",
    "  A = [-200, -100, -170, 15]\n",
    "  a = [-1, -1, -6.5, 0.7]\n",
    "  b = [0, 0, 11, 0.6]\n",
    "  c = [-10, -10, -6.5, 0.7]\n",
    "  x0 = [1, 0, -0.5, -1.0]\n",
    "  y0 = [0, 0.5, 1.5, 1]\n",
    "  value = 0\n",
    "  for k in range(0, 4):\n",
    "    # Scale the function by 0.1 to make plotting easier.\n",
    "    value += 0.1 * A[k] * exp( a[k] * pow(x-x0[k], 2.0) + b[k] * (x-x0[k]) * (y-y0[k]) + c[k] * pow(y-y0[k], 2.0))\n",
    "  return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4GfIwnIKU9E-"
   },
   "source": [
    "## Generate Training Data\n",
    "\n",
    "Next, we need to generate data points to train the neural network. The training data will be generated using the Müller-Brown Potential and a range of x and y values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WIEw90Hx9XMr",
    "outputId": "73aa645c-5ed6-47ec-8ea1-b526d2539e03"
   },
   "outputs": [],
   "source": [
    "# Generate a set of x and y values on a regular grid\n",
    "xx = np.arange(-1.8, 1.4, 0.1)\n",
    "yy = np.arange(-0.4, 2.4, 0.1)\n",
    "X, Y = np.meshgrid(xx, yy)\n",
    "\n",
    "xy, xy_truncated = [], []\n",
    "e, e_truncated = [], []\n",
    "\n",
    "for y in yy:\n",
    "  for x in xx:\n",
    "    v = mueller_brown_potential(x,y) # Now using x and y values from the xx and yy arrays.\n",
    "    e.append(v) # Storing potential energy values in the 'e' array.\n",
    "    xy.append([x,y])\n",
    "    if v < 10:  # Keep only low-energy points for training.\n",
    "      xy_truncated.append([x,y])\n",
    "      e_truncated.append(v)\n",
    "\n",
    "# Reshape 'e' array so that we can plot our data on a 2-D surface that is len(xx) by len(yy).\n",
    "E = np.reshape(e,(len(yy),-1))\n",
    "\n",
    "print(\"E_min:\", np.amin(E), \"E_max:\", np.amax(E))\n",
    "print(\"Size of test set:\", len(e))\n",
    "print(\"Size of training set:\", len(e_truncated))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GHmBKzxwVRGf"
   },
   "source": [
    "### Visualizing Data: 3D Surface\n",
    "\n",
    "We will now create a 3-D plot of our training data. To make the plot more readable, we will replace the points that have extremely high energy with nan (not a number). This will keep our $Z$ array the same shape and help us ignore the high energy region that we are not interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "fj9-VeCjWRPR",
    "outputId": "36501e9d-7c18-41ad-8787-345800f90ad5"
   },
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Surface(z=E, x=X, y=Y, colorscale='rainbow', cmin=-15, cmax=9)])\n",
    "fig.update_traces(contours_z=dict(show=True, project_z=True))\n",
    "fig.update_layout(title='Mueller-Brown Potential', width=500, height=500,\n",
    "                  scene = dict(\n",
    "                  zaxis_title=\"E\",\n",
    "                  zaxis = dict(dtick=3, range=[-15, 15]),\n",
    "                  camera_eye = dict(x=-1.2, y=-1.2, z=1.2)\n",
    "                  ))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S_BieFeHXuD7"
   },
   "source": [
    "### Visualizing Data: Contour Surface\n",
    "\n",
    "To allow for an easier visualization of the potential energy surface, we can generate a 2-D contour surface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "id": "me07-Xz19jGO",
    "outputId": "70268012-626e-478e-b545-29ac2ec3f37c"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(3,2.5), dpi=150)\n",
    "levels = [-12, -8, -4, 0, 4, 8, 10]\n",
    "ct = plt.contour(X, Y, E, levels, colors='k')\n",
    "plt.clabel(ct, inline=True, fmt='%3.0f', fontsize=8)\n",
    "ct = plt.contourf(X, Y, E, levels, cmap=plt.cm.rainbow, extend='both', vmin=-15, vmax=0)\n",
    "plt.xlabel(\"x\", labelpad=-0.75)\n",
    "plt.ylabel(\"y\", labelpad=2.5)\n",
    "plt.tick_params(axis='both', pad=2,labelsize=8)\n",
    "cbar = plt.colorbar()\n",
    "cbar.ax.tick_params(labelsize=8)\n",
    "plt.title('Müeller Brown Contour Surface', fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o5BkUIk5YK4i"
   },
   "source": [
    "## Loading PyTorch and Training Data\n",
    "\n",
    "After installing and importing pytorch, we will save our training data as a tensor data set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LxoMnpPeDlYg",
    "outputId": "0141498d-991e-49b1-b19e-a9ed53b7d2e2"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "\n",
    "dataset = TensorDataset(Tensor(xy_truncated), Tensor(e_truncated))\n",
    "train_dataset, test_dataset = random_split(dataset, [0.7, 0.3])\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "print(\"Size of training set:\", len(train_loader.dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LQUmBoB2cT4s"
   },
   "source": [
    "### Defining the Neural Network Class\n",
    "\n",
    "Here we define our neural network as a Python class. A function ($\\it{train\\_loop}$) is used to loop through our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z3Si6tnBFj93"
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, n=20):  #n is the number of neurons for the first layer\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(2,n), # Linear function taking 2 inputs and outputs data for n neurons.\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(n, 1) # Linear function taking data from n neurons and producing one output value.\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer, epoch):\n",
    "\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred.squeeze(), y)\n",
    "\n",
    "        # Backpropagation - using the gradients of the loss function to update the weights and biases.\n",
    "        optimizer.zero_grad() # Zero out the gradients from the previous iteration to replace them.\n",
    "        loss.backward() # Update the gradients of the loss function.\n",
    "        optimizer.step() # Uses step() to optimize the weights and biases with the updated gradients.\n",
    "\n",
    "        if batch % 32 == 0 and epoch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"epoch: {epoch:>4d} loss: {loss:>7.3f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TXpLmuWBcbpg"
   },
   "source": [
    "## Training the Model\n",
    "\n",
    "Now we can train the neural network model. We will finish our training when the desired number of epochs has been reached. We will also define other hyper-parameters used for the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PGry3oNqGjof",
    "outputId": "45bb5715-7412-4746-b956-2159d34429c5"
   },
   "outputs": [],
   "source": [
    "n_hidden = 32\n",
    "learning_rate = 1e-2\n",
    "epochs = 2000\n",
    "\n",
    "model = NeuralNetwork(n_hidden)\n",
    "loss_fn = F.mse_loss\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loop(train_loader, model, loss_fn, optimizer, epoch)\n",
    "\n",
    "print(\"Done with Training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aNfktUgEc17B"
   },
   "source": [
    "## Plotting Reference, Predicted, and Difference Surfaces\n",
    "\n",
    "Finally, we will plot the Müller-Brown potential energy surface using the analytical function (reference), using the predicted values from the neural network (predicted), and we will show the difference between the predicted and reference surfaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "fudclASTHAaO",
    "outputId": "bfbc79e4-b81d-468a-f436-9d063790c17a"
   },
   "outputs": [],
   "source": [
    "def show_surface(model):\n",
    "\n",
    "  e_pred = model(Tensor(xy))\n",
    "  E_pred = np.reshape(e_pred.detach().numpy(),(len(yy),-1))\n",
    "  Ediff = np.subtract(E_pred, E)\n",
    "\n",
    "  fig = plt.figure(figsize=(3,7.5), dpi=150)\n",
    "\n",
    "\n",
    "  plt.subplot(3, 1, 1)\n",
    "  levels = [-12, -8, -4, 0, 4, 8]\n",
    "  ct = plt.contour(X, Y, E, levels, colors='k')\n",
    "  plt.clabel(ct, inline=True, fmt='%3.0f', fontsize=8)\n",
    "  ct = plt.contourf(X, Y, E, levels, cmap=plt.cm.rainbow, extend='both', vmin=-15, vmax=0)\n",
    "  plt.title(\"(a) Reference\", fontsize=8)\n",
    "  plt.xlabel(\"x\", labelpad=-0.75)\n",
    "  plt.ylabel(\"y\", labelpad=2.5)\n",
    "  plt.tick_params(axis='both', pad=2,labelsize=8)\n",
    "  cbar= plt.colorbar()\n",
    "  cbar.ax.tick_params(labelsize=8)\n",
    "\n",
    "  plt.subplot(3, 1, 2)\n",
    "  ct = plt.contour(X, Y, E_pred, levels, colors='k')\n",
    "  plt.clabel(ct, inline=True, fmt='%3.0f', fontsize=8)\n",
    "  ct = plt.contourf(X, Y, E_pred, levels, cmap=plt.cm.rainbow, extend='both', vmin=-15, vmax=0)\n",
    "  plt.title(\"(b) Predicted\", fontsize=8)\n",
    "  plt.xlabel(\"x\", labelpad=-0.75)\n",
    "  plt.ylabel(\"y\", labelpad=2.5)\n",
    "  plt.tick_params(axis='both', pad=2,labelsize=8)\n",
    "  cbar= plt.colorbar()\n",
    "  cbar.ax.tick_params(labelsize=8)\n",
    "\n",
    "  plt.subplot(3, 1, 3)\n",
    "  levels = [-4, -2, 0, 2, 4]\n",
    "  ct = plt.contour(X, Y, Ediff, levels, colors='k')\n",
    "  plt.clabel(ct, inline=True, fmt='%3.0f', fontsize=8)\n",
    "  ct = plt.contourf(X, Y, Ediff, levels, cmap=plt.cm.rainbow, extend='both', vmin=-4, vmax=4)\n",
    "  plt.title(\"(c) Difference\", fontsize=8)\n",
    "  plt.xlabel(\"x\", labelpad=-0.75)\n",
    "  plt.ylabel(\"y\", labelpad=2.5)\n",
    "  print(\"diff, min, max:\", np.amin(Ediff), np.amax(Ediff))\n",
    "  plt.tick_params(axis='both', pad=2,labelsize=8)\n",
    "  cbar= plt.colorbar()\n",
    "  cbar.ax.tick_params(labelsize=8)\n",
    "\n",
    "  plt.tight_layout()\n",
    "\n",
    "  plt.show()\n",
    "\n",
    "show_surface(model)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "cd78fef2128015050713e82ca51c6520b11aee7c9ee8df750520bbbc7384cbaa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
